{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "3937052c-4957-4bf4-80c6-2ee18b30a416",
      "metadata": {
        "id": "3937052c-4957-4bf4-80c6-2ee18b30a416"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# Then Set Random Seeds\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "# Then run the Enable Deterministic Operations Function\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras import layers, optimizers, regularizers\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import set_config\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "set_config(transform_output='pandas')\n",
        "pd.set_option('display.max_colwidth', 250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "244d14dd-b7a4-422a-9117-e962cf8a129f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "244d14dd-b7a4-422a-9117-e962cf8a129f",
        "outputId": "807dc76e-96cc-4db9-99a4-413fb3368eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  review_id  movie_id    imdb_id          original_title  \\\n",
              "0  57086ff5c3a3681d29001512      7443  tt0120630             Chicken Run   \n",
              "1  57b2d23dc3a36837d7000b14       955  tt0120755  Mission: Impossible II   \n",
              "\n",
              "                                                                                                                                                                                                                                                      review  \\\n",
              "0  A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...   \n",
              "1  The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...   \n",
              "\n",
              "   rating  \\\n",
              "0     9.0   \n",
              "1     3.0   \n",
              "\n",
              "                                                                                                                                                                                                                                                      tokens  \\\n",
              "0  A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...   \n",
              "1  The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...   \n",
              "\n",
              "        target  \\\n",
              "0  High-rating   \n",
              "1   Low-rating   \n",
              "\n",
              "                                                                                                                                                                                                                                                   Tokenized  \\\n",
              "0  ['A', 'guilty', 'pleasure', 'for', 'me', 'personally,', 'as', 'I', 'love', 'both', \"'The\", 'Great', \"Escape'\", 'and', 'most', 'of', 'the', 'works', 'I', 'have', 'seen,', 'over', 'the', 'years,', 'from', 'this', 'rightfully-esteemed', 'British', '...   \n",
              "1  ['The', 'first', 'underwhelmed', 'me,', 'but', 'this', 'one', 'straight-up', 'bored', 'me.', 'Again,', 'of', 'course', 'seeing', 'Hunt', 'climb', 'a', 'mountain', 'without', 'a', 'harness', 'is', 'impressive', 'sure.', 'And', 'I', 'even', 'quite'...   \n",
              "\n",
              "                                                                                                                                                                                                                                                  Lemmatized  \\\n",
              "0                ['guilty', 'pleasure', 'personally', 'love', 'the', 'Great', 'Escape', 'of', 'the', 'work', 'see', 'the', 'year', 'rightfully', 'esteem', 'british', 'animation', 'company', 'highly', 'recommend', 'child', 'adult', 'enjoy', 'animation']   \n",
              "1  ['the', 'underwhelme', 'straight', 'bore', 'of', 'course', 'see', 'Hunt', 'climb', 'mountain', 'harness', 'be', 'impressive', 'sure', 'like', 'the', 'idea', 'the', 'villain', 'of', 'the', 'piece', 'angle', 'woefully', 'underdeveloped', '\\r\\n\\r\\n'...   \n",
              "\n",
              "                                                                                                                                                                                                                                               Tokens-joined  \\\n",
              "0  A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...   \n",
              "1  The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...   \n",
              "\n",
              "                                                                                                                                                                                                                                               Lemmas-joined  \n",
              "0                                                                                         guilty pleasure personally love the Great Escape of the work see the year rightfully esteem british animation company highly recommend child adult enjoy animation  \n",
              "1  the underwhelme straight bore of course see Hunt climb mountain harness be impressive sure like the idea the villain of the piece angle woefully underdeveloped \\r\\n\\r\\n set in predominantly Australia to grab attention say cause pretty biased come...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1839c0ef-c0ee-4843-a30d-eba73dc37083\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_title</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>tokens</th>\n",
              "      <th>target</th>\n",
              "      <th>Tokenized</th>\n",
              "      <th>Lemmatized</th>\n",
              "      <th>Tokens-joined</th>\n",
              "      <th>Lemmas-joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57086ff5c3a3681d29001512</td>\n",
              "      <td>7443</td>\n",
              "      <td>tt0120630</td>\n",
              "      <td>Chicken Run</td>\n",
              "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...</td>\n",
              "      <td>High-rating</td>\n",
              "      <td>['A', 'guilty', 'pleasure', 'for', 'me', 'personally,', 'as', 'I', 'love', 'both', \"'The\", 'Great', \"Escape'\", 'and', 'most', 'of', 'the', 'works', 'I', 'have', 'seen,', 'over', 'the', 'years,', 'from', 'this', 'rightfully-esteemed', 'British', '...</td>\n",
              "      <td>['guilty', 'pleasure', 'personally', 'love', 'the', 'Great', 'Escape', 'of', 'the', 'work', 'see', 'the', 'year', 'rightfully', 'esteem', 'british', 'animation', 'company', 'highly', 'recommend', 'child', 'adult', 'enjoy', 'animation']</td>\n",
              "      <td>A guilty pleasure for me personally, as I love both 'The Great Escape' and most of the works I have seen, over the years, from this rightfully-esteemed British animation company. Highly recommended both for children and for adults who enjoy anima...</td>\n",
              "      <td>guilty pleasure personally love the Great Escape of the work see the year rightfully esteem british animation company highly recommend child adult enjoy animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57b2d23dc3a36837d7000b14</td>\n",
              "      <td>955</td>\n",
              "      <td>tt0120755</td>\n",
              "      <td>Mission: Impossible II</td>\n",
              "      <td>The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...</td>\n",
              "      <td>Low-rating</td>\n",
              "      <td>['The', 'first', 'underwhelmed', 'me,', 'but', 'this', 'one', 'straight-up', 'bored', 'me.', 'Again,', 'of', 'course', 'seeing', 'Hunt', 'climb', 'a', 'mountain', 'without', 'a', 'harness', 'is', 'impressive', 'sure.', 'And', 'I', 'even', 'quite'...</td>\n",
              "      <td>['the', 'underwhelme', 'straight', 'bore', 'of', 'course', 'see', 'Hunt', 'climb', 'mountain', 'harness', 'be', 'impressive', 'sure', 'like', 'the', 'idea', 'the', 'villain', 'of', 'the', 'piece', 'angle', 'woefully', 'underdeveloped', '\\r\\n\\r\\n'...</td>\n",
              "      <td>The first underwhelmed me, but this one straight-up bored me. Again, of course seeing Hunt climb a mountain without a harness is impressive sure. And I even quite liked the idea behind the villain of the piece (though even that angle was woefully...</td>\n",
              "      <td>the underwhelme straight bore of course see Hunt climb mountain harness be impressive sure like the idea the villain of the piece angle woefully underdeveloped \\r\\n\\r\\n set in predominantly Australia to grab attention say cause pretty biased come...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1839c0ef-c0ee-4843-a30d-eba73dc37083')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1839c0ef-c0ee-4843-a30d-eba73dc37083 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1839c0ef-c0ee-4843-a30d-eba73dc37083');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-011289d0-1c47-4aeb-a5ee-e2ffa0efd868\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-011289d0-1c47-4aeb-a5ee-e2ffa0efd868')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-011289d0-1c47-4aeb-a5ee-e2ffa0efd868 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2419,\n  \"fields\": [\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2418,\n        \"samples\": [\n          \"5fff7be5678259003f9c26bd\",\n          \"5d6778d16743fa0011d62249\",\n          \"63bf624d8efe7300f0a2224e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movie_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 237156,\n        \"min\": 12,\n        \"max\": 1161406,\n        \"num_unique_values\": 1407,\n        \"samples\": [\n          29963,\n          321258,\n          549053\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imdb_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1407,\n        \"samples\": [\n          \"tt0810784\",\n          \"tt3882082\",\n          \"tt8623904\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1401,\n        \"samples\": [\n          \"Frozen II\",\n          \"I, Tonya\",\n          \"The Fast and the Furious\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2408,\n        \"samples\": [\n          \"**By: Louisa Moore / www.ScreenZealots.com**\\r\\n\\r\\nImportant subject matter doesn\\u2019t always translate to a good movie, and \\u201cShe Said\\u201d is a botched attempt at retelling the true story of two New York Times reporters who took down the infamous Hollywood abuser, Harvey Weinstein. It\\u2019s something with which the industry is very familiar, and the years of sexual misconduct that the two women uncovered is horrifying. It was one of the most important articles to ever run in the newspaper, but this story would be better suited to the page and not the screen.\\r\\n\\r\\nThe film follows writers Megan Twohey (Carey Mulligan) and Jodi Kantor (Zoe Kazan) as they investigate the Miramax movie mogul, trying repeatedly to get big name actresses to go on the record to expose Weinstein\\u2019s gross abuse of power. Instead of offering new insight, director Maria Schrader uses the same old newsroom clich\\u00e9s to create a pedestrian investigative journalism film. It\\u2019s procedural, boring, and repetitive, with a series of scenes featuring the two leads making phone calls, writing or reading text messages, and sitting in editorial meetings. Of course, this is less than interesting because the story isn\\u2019t cinematic: it\\u2019s dull.\\r\\n\\r\\nThe film touches on the more interesting aspects of working as a woman in Hollywood, as many of Weinstein\\u2019s victims refused to be named on the record because they were terrified they\\u2019d never work again. This did happen more often than not, and he either bought or forced their silence. Perhaps if screenwriter Rebecca Lenkiewicz had decided to focus more on the personal dilemmas and fallout his victims faced rather than only briefly touch on them, this would have been a stronger and more powerful movie.\\r\\n\\r\\nEven worse, the film doesn\\u2019t feel timely. The decision to tell this story now seems dated and past its expiration date. Women will always remember the #MeToo movement and it will go down in history as one of the most important feminist campaigns of the 2000s, but many of us would rather forget about Weinstein while he rots away in jail.\\r\\n\\r\\nHere\\u2019s where my biggest problem with the film comes in: the story leaves a really bad taste in my mouth, especially when you stop to realize that many of Weinstein\\u2019s employees, friends, and peers either aided in covering up his crimes or even worse, willfully looked the other way. Harvey\\u2019s touchy nature and treatment of subordinates was the worst kept secret in Hollywood circles. He was as creep, and many who met him were uncomfortable being in his presence. It feels a bit disingenuous (or perhaps just a bit ironic) to make a movie about it, even if the story\\u2019s focus is on the two reporters.\\r\\n\\r\\nThe better parts of the narrative inspire with the proof of the power of journalism to encourage change, and Kantor and Twohey absolutely played a huge part in giving women who were victimized the courage to come forward. Mulligan gives a strong performance, but it\\u2019s a shame she didn\\u2019t have an equally robust script to work with. Both of the leads feel wasted, especially when they are called on to do little more than rattle off facts and name-drop big actresses who came forward to expose the year of abusive behavior by Weinstein. None of this is a substitute for compelling drama, and \\u201cShe Said\\u201d fades into the void of forgettable procedural journalism films.\",\n          \"Okay, seriously, when is the real \\\"Halloween Ends\\\" be released? What I saw for the bulk was some lame CW-like story. I have to think at this point David Gordon Green and the writer crew are just pulling a prank. I half expected a post-credit scene with Impractical Jokers...\\r\\n\\r\\nI don't even know what to say. I had low expectations going in given how much I disliked Halloween Kills but Ends didn't even meet the lows of the lows. Really dumb. **1.0/5**\",\n          \"Well, the soundtrack rocked. It was wonderfully classic. Wonderfully sentimental. Wonderfully awesome again. And it was fun how music suddenly became their thing as a team.\\r\\n\\r\\nBaby Groot was fun, funny, and adorable all at the same time...and it worked because he was also a lot more violent than the adult Groot, which made it stand far and away from the overly saccharin nightmare that he could have been.\\r\\n\\r\\nStar Lord unfortunately matured a bit. He wasn't anywhere near the...can I say d**che bag here? Jerk is too strong of a word and you never really got the impression that he was really an idiot in the first one. In any case it was that annoying quality that made him such a great character in the first movie.\\r\\n\\r\\nIn the sequel Peter has grown and some of the traits that made him so fun to watch are still there...just muted as he became more of an adult.\\r\\n\\r\\nIt works for the plot, and he is still a lot of fun to watch, but a part of the appeal was that he was sort of Peter pan and it hurts wa6tching someone like that grow.\\r\\n\\r\\nThe only really weak point was Mantis and only really because she was clearly going to join the team and clearly not doing much of anything.\\r\\n\\r\\nAs the whole, you have another departure away from the overly serious...or sometimes moderately serious cape flicks...which a refreshing getaway, so long as its understood that Guardians and the like are departures from the norm and not a harbinger of Batman & Robin camp again.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4648697282272694,\n        \"min\": 0.5,\n        \"max\": 10.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          9.5,\n          9.0,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2408,\n        \"samples\": [\n          \"**By: Louisa Moore / www.ScreenZealots.com**\\r\\n\\r\\nImportant subject matter doesn\\u2019t always translate to a good movie, and \\u201cShe Said\\u201d is a botched attempt at retelling the true story of two New York Times reporters who took down the infamous Hollywood abuser, Harvey Weinstein. It\\u2019s something with which the industry is very familiar, and the years of sexual misconduct that the two women uncovered is horrifying. It was one of the most important articles to ever run in the newspaper, but this story would be better suited to the page and not the screen.\\r\\n\\r\\nThe film follows writers Megan Twohey (Carey Mulligan) and Jodi Kantor (Zoe Kazan) as they investigate the Miramax movie mogul, trying repeatedly to get big name actresses to go on the record to expose Weinstein\\u2019s gross abuse of power. Instead of offering new insight, director Maria Schrader uses the same old newsroom clich\\u00e9s to create a pedestrian investigative journalism film. It\\u2019s procedural, boring, and repetitive, with a series of scenes featuring the two leads making phone calls, writing or reading text messages, and sitting in editorial meetings. Of course, this is less than interesting because the story isn\\u2019t cinematic: it\\u2019s dull.\\r\\n\\r\\nThe film touches on the more interesting aspects of working as a woman in Hollywood, as many of Weinstein\\u2019s victims refused to be named on the record because they were terrified they\\u2019d never work again. This did happen more often than not, and he either bought or forced their silence. Perhaps if screenwriter Rebecca Lenkiewicz had decided to focus more on the personal dilemmas and fallout his victims faced rather than only briefly touch on them, this would have been a stronger and more powerful movie.\\r\\n\\r\\nEven worse, the film doesn\\u2019t feel timely. The decision to tell this story now seems dated and past its expiration date. Women will always remember the #MeToo movement and it will go down in history as one of the most important feminist campaigns of the 2000s, but many of us would rather forget about Weinstein while he rots away in jail.\\r\\n\\r\\nHere\\u2019s where my biggest problem with the film comes in: the story leaves a really bad taste in my mouth, especially when you stop to realize that many of Weinstein\\u2019s employees, friends, and peers either aided in covering up his crimes or even worse, willfully looked the other way. Harvey\\u2019s touchy nature and treatment of subordinates was the worst kept secret in Hollywood circles. He was as creep, and many who met him were uncomfortable being in his presence. It feels a bit disingenuous (or perhaps just a bit ironic) to make a movie about it, even if the story\\u2019s focus is on the two reporters.\\r\\n\\r\\nThe better parts of the narrative inspire with the proof of the power of journalism to encourage change, and Kantor and Twohey absolutely played a huge part in giving women who were victimized the courage to come forward. Mulligan gives a strong performance, but it\\u2019s a shame she didn\\u2019t have an equally robust script to work with. Both of the leads feel wasted, especially when they are called on to do little more than rattle off facts and name-drop big actresses who came forward to expose the year of abusive behavior by Weinstein. None of this is a substitute for compelling drama, and \\u201cShe Said\\u201d fades into the void of forgettable procedural journalism films.\",\n          \"Okay, seriously, when is the real \\\"Halloween Ends\\\" be released? What I saw for the bulk was some lame CW-like story. I have to think at this point David Gordon Green and the writer crew are just pulling a prank. I half expected a post-credit scene with Impractical Jokers...\\r\\n\\r\\nI don't even know what to say. I had low expectations going in given how much I disliked Halloween Kills but Ends didn't even meet the lows of the lows. Really dumb. **1.0/5**\",\n          \"Well, the soundtrack rocked. It was wonderfully classic. Wonderfully sentimental. Wonderfully awesome again. And it was fun how music suddenly became their thing as a team.\\r\\n\\r\\nBaby Groot was fun, funny, and adorable all at the same time...and it worked because he was also a lot more violent than the adult Groot, which made it stand far and away from the overly saccharin nightmare that he could have been.\\r\\n\\r\\nStar Lord unfortunately matured a bit. He wasn't anywhere near the...can I say d**che bag here? Jerk is too strong of a word and you never really got the impression that he was really an idiot in the first one. In any case it was that annoying quality that made him such a great character in the first movie.\\r\\n\\r\\nIn the sequel Peter has grown and some of the traits that made him so fun to watch are still there...just muted as he became more of an adult.\\r\\n\\r\\nIt works for the plot, and he is still a lot of fun to watch, but a part of the appeal was that he was sort of Peter pan and it hurts wa6tching someone like that grow.\\r\\n\\r\\nThe only really weak point was Mantis and only really because she was clearly going to join the team and clearly not doing much of anything.\\r\\n\\r\\nAs the whole, you have another departure away from the overly serious...or sometimes moderately serious cape flicks...which a refreshing getaway, so long as its understood that Guardians and the like are departures from the norm and not a harbinger of Batman & Robin camp again.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Low-rating\",\n          \"High-rating\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokenized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2407,\n        \"samples\": [\n          \"['**By:', 'Louisa', 'Moore', '/', 'www.ScreenZealots.com**', 'Important', 'subject', 'matter', 'doesn\\u2019t', 'always', 'translate', 'to', 'a', 'good', 'movie,', 'and', '\\u201cShe', 'Said\\u201d', 'is', 'a', 'botched', 'attempt', 'at', 'retelling', 'the', 'true', 'story', 'of', 'two', 'New', 'York', 'Times', 'reporters', 'who', 'took', 'down', 'the', 'infamous', 'Hollywood', 'abuser,', 'Harvey', 'Weinstein.', 'It\\u2019s', 'something', 'with', 'which', 'the', 'industry', 'is', 'very', 'familiar,', 'and', 'the', 'years', 'of', 'sexual', 'misconduct', 'that', 'the', 'two', 'women', 'uncovered', 'is', 'horrifying.', 'It', 'was', 'one', 'of', 'the', 'most', 'important', 'articles', 'to', 'ever', 'run', 'in', 'the', 'newspaper,', 'but', 'this', 'story', 'would', 'be', 'better', 'suited', 'to', 'the', 'page', 'and', 'not', 'the', 'screen.', 'The', 'film', 'follows', 'writers', 'Megan', 'Twohey', '(Carey', 'Mulligan)', 'and', 'Jodi', 'Kantor', '(Zoe', 'Kazan)', 'as', 'they', 'investigate', 'the', 'Miramax', 'movie', 'mogul,', 'trying', 'repeatedly', 'to', 'get', 'big', 'name', 'actresses', 'to', 'go', 'on', 'the', 'record', 'to', 'expose', 'Weinstein\\u2019s', 'gross', 'abuse', 'of', 'power.', 'Instead', 'of', 'offering', 'new', 'insight,', 'director', 'Maria', 'Schrader', 'uses', 'the', 'same', 'old', 'newsroom', 'clich\\u00e9s', 'to', 'create', 'a', 'pedestrian', 'investigative', 'journalism', 'film.', 'It\\u2019s', 'procedural,', 'boring,', 'and', 'repetitive,', 'with', 'a', 'series', 'of', 'scenes', 'featuring', 'the', 'two', 'leads', 'making', 'phone', 'calls,', 'writing', 'or', 'reading', 'text', 'messages,', 'and', 'sitting', 'in', 'editorial', 'meetings.', 'Of', 'course,', 'this', 'is', 'less', 'than', 'interesting', 'because', 'the', 'story', 'isn\\u2019t', 'cinematic:', 'it\\u2019s', 'dull.', 'The', 'film', 'touches', 'on', 'the', 'more', 'interesting', 'aspects', 'of', 'working', 'as', 'a', 'woman', 'in', 'Hollywood,', 'as', 'many', 'of', 'Weinstein\\u2019s', 'victims', 'refused', 'to', 'be', 'named', 'on', 'the', 'record', 'because', 'they', 'were', 'terrified', 'they\\u2019d', 'never', 'work', 'again.', 'This', 'did', 'happen', 'more', 'often', 'than', 'not,', 'and', 'he', 'either', 'bought', 'or', 'forced', 'their', 'silence.', 'Perhaps', 'if', 'screenwriter', 'Rebecca', 'Lenkiewicz', 'had', 'decided', 'to', 'focus', 'more', 'on', 'the', 'personal', 'dilemmas', 'and', 'fallout', 'his', 'victims', 'faced', 'rather', 'than', 'only', 'briefly', 'touch', 'on', 'them,', 'this', 'would', 'have', 'been', 'a', 'stronger', 'and', 'more', 'powerful', 'movie.', 'Even', 'worse,', 'the', 'film', 'doesn\\u2019t', 'feel', 'timely.', 'The', 'decision', 'to', 'tell', 'this', 'story', 'now', 'seems', 'dated', 'and', 'past', 'its', 'expiration', 'date.', 'Women', 'will', 'always', 'remember', 'the', '#MeToo', 'movement', 'and', 'it', 'will', 'go', 'down', 'in', 'history', 'as', 'one', 'of', 'the', 'most', 'important', 'feminist', 'campaigns', 'of', 'the', '2000s,', 'but', 'many', 'of', 'us', 'would', 'rather', 'forget', 'about', 'Weinstein', 'while', 'he', 'rots', 'away', 'in', 'jail.', 'Here\\u2019s', 'where', 'my', 'biggest', 'problem', 'with', 'the', 'film', 'comes', 'in:', 'the', 'story', 'leaves', 'a', 'really', 'bad', 'taste', 'in', 'my', 'mouth,', 'especially', 'when', 'you', 'stop', 'to', 'realize', 'that', 'many', 'of', 'Weinstein\\u2019s', 'employees,', 'friends,', 'and', 'peers', 'either', 'aided', 'in', 'covering', 'up', 'his', 'crimes', 'or', 'even', 'worse,', 'willfully', 'looked', 'the', 'other', 'way.', 'Harvey\\u2019s', 'touchy', 'nature', 'and', 'treatment', 'of', 'subordinates', 'was', 'the', 'worst', 'kept', 'secret', 'in', 'Hollywood', 'circles.', 'He', 'was', 'as', 'creep,', 'and', 'many', 'who', 'met', 'him', 'were', 'uncomfortable', 'being', 'in', 'his', 'presence.', 'It', 'feels', 'a', 'bit', 'disingenuous', '(or', 'perhaps', 'just', 'a', 'bit', 'ironic)', 'to', 'make', 'a', 'movie', 'about', 'it,', 'even', 'if', 'the', 'story\\u2019s', 'focus', 'is', 'on', 'the', 'two', 'reporters.', 'The', 'better', 'parts', 'of', 'the', 'narrative', 'inspire', 'with', 'the', 'proof', 'of', 'the', 'power', 'of', 'journalism', 'to', 'encourage', 'change,', 'and', 'Kantor', 'and', 'Twohey', 'absolutely', 'played', 'a', 'huge', 'part', 'in', 'giving', 'women', 'who', 'were', 'victimized', 'the', 'courage', 'to', 'come', 'forward.', 'Mulligan', 'gives', 'a', 'strong', 'performance,', 'but', 'it\\u2019s', 'a', 'shame', 'she', 'didn\\u2019t', 'have', 'an', 'equally', 'robust', 'script', 'to', 'work', 'with.', 'Both', 'of', 'the', 'leads', 'feel', 'wasted,', 'especially', 'when', 'they', 'are', 'called', 'on', 'to', 'do', 'little', 'more', 'than', 'rattle', 'off', 'facts', 'and', 'name-drop', 'big', 'actresses', 'who', 'came', 'forward', 'to', 'expose', 'the', 'year', 'of', 'abusive', 'behavior', 'by', 'Weinstein.', 'None', 'of', 'this', 'is', 'a', 'substitute', 'for', 'compelling', 'drama,', 'and', '\\u201cShe', 'Said\\u201d', 'fades', 'into', 'the', 'void', 'of', 'forgettable', 'procedural', 'journalism', 'films.']\",\n          \"['I', 're-watched', 'the', 'original', '_Fantastic', 'Beasts_', 'today', 'to', 'prep', 'for', '_Crimes', 'of', 'Grindelwald_', 'and', 'it', 'made', 'me', 'realise', 'that', 'the', 'only', 'reason', 'I', 'gave', 'that', 'first', 'film', 'a', 'positive', 'review', 'was', 'because', 'of', 'Queenie', 'Goldstein.', \\\"She's\\\", 'just', '**such**', 'a', 'sweetheart.', 'Her', 'character', \\\"wasn't\\\", 'the', '**only**', 'thing', 'I', 'liked', 'about', 'that', 'movie,', 'but', 'without', 'her,', 'it', 'still', 'gets', 'pushed', 'down', 'into', 'Rotten.', 'So', 'when', 'they', 'took', 'her', 'in', 'this', 'one', 'and', 'first', 'made', 'her', 'a', 'rapist', 'and', 'then', 'a', 'Nazis,', 'I', 'was', 'uh...', 'Not', 'exactly', 'stoked.', 'But', \\\"that's\\\", 'a', 'personal', 'thing,', 'and', 'I', 'try', 'to,', 'at', 'least', 'partially,', 'put', 'that', 'aside', 'and', 'review', 'on', 'things', 'like', 'technical', 'aspect.', 'And', 'in', 'that', 'Avenue,', '_Crimes', 'of', 'Grindelwald_', 'is', 'an', '**abysmal**', 'failure.', 'This', 'is', 'not', 'the', 'outright', 'worst', 'film', 'of', 'the', 'year,', 'but', 'it', 'was', 'definitely', 'the', 'worst', 'one', \\\"I've\\\", 'seen', 'in', 'cinemas', 'for', 'a', 'long', 'damn', 'time.', '_Final', 'rating:\\u2605\\u00bd:', '-', 'Boring/disappointing.', 'Avoid', 'where', 'possible._']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2401,\n        \"samples\": [\n          \"['safe', 'feel', '\\\\r\\\\n\\\\r\\\\n', 'Bond', '23', '007', 'to', 'literally', 'come', 'the', 'dead', 'steal', 'hard', 'drive', 'make', 'M', 'Dench', 'look', 'bad', 'time', 'face', 'past', 'come', 'home', 'blood', 'thirsty', 'view', '\\\\r\\\\n\\\\r\\\\n', 'be', 'sure', 'fire', 'fact', 'in', 'cinema', 'dispute', 'of', 'James', 'Bond', 'film', 'bondphile', 'agree', 'corner', 'of', 'the', 'spectrum', 'come', 'argument', 'say', 'bond', 'film', 'be', 'gritty', 'fun', 'sex', 'action', 'fantastical', 'stunt', 'etc', 'etc', 'etc', 'fine', 'of', 'course', 'peccadillo', 'prefer', 'in', 'bond', 'movie', 'live', 'in', 'different', 'time', 'the', 'world', 'change', 'Bond', 'the', 'ultimate', 'Bond', 'want', 'be', '21st', 'Century', 'Bond', 'new', 'era', 'of', '007', 'be', 'make', 'Skyfall', 'the', 'bolder', 'braver', 'mark', 'the', '50th', 'anniversary', 'blend', 'the', 'old', 'the', 'new', 'achieve', 'brilliant', 'result', '\\\\r\\\\n\\\\r\\\\n', 'Skyfall', 'allow', 'to', 'bathe', 'in', 'nostalgia', 'whilst', 'force', 'to', 're-', 'evaluate', 'in', 'term', 'of', 'beloved', 'super', 'secret', 'agent', 'of', 'the', 'great', 'thing', 'Bond', 'be', 'be', 'bubble', 'current', 'of', 'time', 'importance', 'delicately', 'perch', 'of', 'James', 'Bond', 'shoulder', 'M', 'etc', 'outdate', 'be', 'the', 'future', 'in', 'need', 'of', 'operative', 'organisation', 'Director', 'Mendes', 'team', 'of', 'the', 'easy', 'option', 'clearly', 'available', 'to', 'to', 'answer', 'the', 'question', 'instead', 'build', 'film', 'Bond', 'M', 'character', 'embrace', 'the', 'tradition', 'of', 'the', 'series', 'hit', 'hard', 'in', 'head', 'heart', '\\\\r\\\\n\\\\r\\\\n', 'the', 'plot', 'of', 'Skyfall', 'write', 'be', 'simple', 'absolutely', 'nail', 'be', 'straight', 'true', 'to', 'Hollywood', 'convention', 'fill', 'the', 'simple', 'plot', 'be', 'series', 'of', 'Bondian', 'delight', 'thrill', 'spill', 'emotionally', 'splinter', 'kill', 'the', 'stunning', 'pre', 'credits', 'sequence', 'see', 'Bond', 'traverse', 'the', 'rooftop', 'of', 'Istanbul', 'motorcycle', 'fight', 'of', 'speeding', 'train', 'to', 'find', 'expendable', 'lead', 'to', 'Daniel', 'Kleinman', 'title', 'credit', 'sequence', 'be', 'fill', 'ominous', 'portent', 'of', 'death', 'blood', 'in', 'turn', 'back', 'the', 'wonderfully', 'Bondian', 'of', 'old', 'title', 'song', 'warble', 'Adele', 'clear', 'point', 'Bond', 'movie', 'be', 'nod', 'to', 'traditional', 'value', 'whilst', 'promise', 'to', 'deliver', 'emotional', 'pain', 'prove', '\\\\r\\\\n\\\\r\\\\n', 'wash', 'bond', 'enter', 'the', 'fray', 'convince', 'dishevel', 'unshaven', 'unfit', 'tough', 'bastard', 'drink', 'hard', 'stare', 'scorpion', 'be', 'soon', 'know', 'be', 'in', 'wonderful', 'physical', 'shape', 'loyal', 'to', 'surrogate', 'mother', 'sure', 'ah', 'the', 'adversary', 'the', 'scene', 'villain', 'to', 'finally', 'Craig', 'bond', 'to', 'fret', 'Javier', 'Bardem', 'perfect', 'Silva', 'cyber', 'terrorist', 'shock', 'of', 'blonde', 'hair', 'nasty', 'dental', 'trick', 'devilish', 'sexiness', 'unnerve', 'interrogation', 'scene', 'to', 'bond', 'cheekily', 'open', 'wink', 'wink', 'possibility', 'be', 'sexual', 'tension', 'in', 'the', 'film', 'steamy', 'shower', 'scene', 'the', 'ongoing', 'banter', 'Naomie', 'Harris', 'excellent', 'Eve', 'positively', 'fizz', 'smirk', 'innuendo', '\\\\r\\\\n\\\\r\\\\n', 'ultimately', 'come', 'to', 'the', 'love', 'man', 'woman', 'the', 'kind', 'be', 'different', 'to', 'the', 'type', 'underpin', 'Bond', 'movie', 'bond', 'kill', 'be', 'kill', 'M', 'marvellous', 'to', 'director', 'able', 'to', 'Judi', 'Dench', 'the', 'direction', 'deserve', 'Bond', 'in', 'Craig', 'magnetic', 'gritty', 'hand', 'respond', 'in', 'kind', 'to', 'deliver', 'half', 'hour', 'good', 'in', 'the', '50', 'year', 'of', 'Bond', 'film', 'know', 'turf', 'be', 'Bond', 'turf', 'time', 'be', 'turf', 'little', 'story', 'come', 'seep', 'bond', 'get', 'to', 'exorcise', 'demon', 'whilst', 'kick', 'considerable', 'ass', 'ready', 'bondphile', 'the', 'emotional', 'wallop', 'see', 'in', 'the', 'good', 'bond', 'movie', 'of', 'old', '\\\\r\\\\n\\\\r\\\\n', 'the', 'bondian', 'trapping', 'exotic', 'locale', 'gorgeous', 'woman', 'speed', 'vehicle', 'fight', 'stupendous', 'stunt', 'bizarre', 'lair', 'ball', 'machismo', 'funny', 'comment', 'review', 'Quantum', 'of', 'Solace', 'pretty', 'ace', 'action', 'film', 'bondian', 'the', 'truth', 'of', 'the', 'matter', 'be', 'Bond', 'need', 'to', 'degree', 'of', 'fun', 'matter', 'grim', 'gritty', 'the', 'story', 'line', 'be', 'thankfully', 'Skyfall', 'be', 'blast', 'Craig', 'surely', 'convince', 'the', 'stubborn', 'of', 'dissenter', 'good', 'bond', 'be', 'have', 'the', 'confidence', 'skill', 'to', 'lace', 'Bond', 'macho', 'broody', 'instinct', 'desert', 'dry', 'wit', 'shrug', 'of', 'the', 'shoulder', 'nonchalance', 'of', 'the', 'camera', 'the', 'tech', 'credit', 'high', 'Deakins', 'prove', 'to', 'be', 'of', 'the', 'ace', 'in', 'the', 'pack', 'capturing', 'of', 'vista', 'be', 'neon', 'city', 'scape', 'mountainous', 'valley', 'eye', 'delight', 'colour', 'tone', 'beautiful', 'promise', 'day', 'golden', 'brown', 'like', 'Deakins', '\\\\r\\\\n\\\\r\\\\n', 'the', 'masterpiece', 'gazillion', 'of', 'hope', 'flaw', 'new', 'Q', 'bit', 'geeky', 'safe', 'finale', 'lack', 'substantial', 'battle', 'the', 'villain', 'remain', 'simple', 'in', 'plot', 'Bond', 'birthday', 'the', 'birthday', 'boy', 'proud', 'the', 'maker', 'new', 'era', 'Bond', 'sure', 'definitely', 'be', 'bad', 'thing', 'know', 'past', 'know', 'future', 'doubt', 'know', 'the', '9/10']\",\n          \"['like', 'the', 'ending', 'give', 'low', 'rating', 'the', 'movie', 'ok', 'keep', 'interested', 'lot', 'of', 'drug', 'use', 'make', 'stupid', 'stuff']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens-joined\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2407,\n        \"samples\": [\n          \"**By: Louisa Moore / www.ScreenZealots.com** Important subject matter doesn\\u2019t always translate to a good movie, and \\u201cShe Said\\u201d is a botched attempt at retelling the true story of two New York Times reporters who took down the infamous Hollywood abuser, Harvey Weinstein. It\\u2019s something with which the industry is very familiar, and the years of sexual misconduct that the two women uncovered is horrifying. It was one of the most important articles to ever run in the newspaper, but this story would be better suited to the page and not the screen. The film follows writers Megan Twohey (Carey Mulligan) and Jodi Kantor (Zoe Kazan) as they investigate the Miramax movie mogul, trying repeatedly to get big name actresses to go on the record to expose Weinstein\\u2019s gross abuse of power. Instead of offering new insight, director Maria Schrader uses the same old newsroom clich\\u00e9s to create a pedestrian investigative journalism film. It\\u2019s procedural, boring, and repetitive, with a series of scenes featuring the two leads making phone calls, writing or reading text messages, and sitting in editorial meetings. Of course, this is less than interesting because the story isn\\u2019t cinematic: it\\u2019s dull. The film touches on the more interesting aspects of working as a woman in Hollywood, as many of Weinstein\\u2019s victims refused to be named on the record because they were terrified they\\u2019d never work again. This did happen more often than not, and he either bought or forced their silence. Perhaps if screenwriter Rebecca Lenkiewicz had decided to focus more on the personal dilemmas and fallout his victims faced rather than only briefly touch on them, this would have been a stronger and more powerful movie. Even worse, the film doesn\\u2019t feel timely. The decision to tell this story now seems dated and past its expiration date. Women will always remember the #MeToo movement and it will go down in history as one of the most important feminist campaigns of the 2000s, but many of us would rather forget about Weinstein while he rots away in jail. Here\\u2019s where my biggest problem with the film comes in: the story leaves a really bad taste in my mouth, especially when you stop to realize that many of Weinstein\\u2019s employees, friends, and peers either aided in covering up his crimes or even worse, willfully looked the other way. Harvey\\u2019s touchy nature and treatment of subordinates was the worst kept secret in Hollywood circles. He was as creep, and many who met him were uncomfortable being in his presence. It feels a bit disingenuous (or perhaps just a bit ironic) to make a movie about it, even if the story\\u2019s focus is on the two reporters. The better parts of the narrative inspire with the proof of the power of journalism to encourage change, and Kantor and Twohey absolutely played a huge part in giving women who were victimized the courage to come forward. Mulligan gives a strong performance, but it\\u2019s a shame she didn\\u2019t have an equally robust script to work with. Both of the leads feel wasted, especially when they are called on to do little more than rattle off facts and name-drop big actresses who came forward to expose the year of abusive behavior by Weinstein. None of this is a substitute for compelling drama, and \\u201cShe Said\\u201d fades into the void of forgettable procedural journalism films.\",\n          \"I re-watched the original _Fantastic Beasts_ today to prep for _Crimes of Grindelwald_ and it made me realise that the only reason I gave that first film a positive review was because of Queenie Goldstein. She's just **such** a sweetheart. Her character wasn't the **only** thing I liked about that movie, but without her, it still gets pushed down into Rotten. So when they took her in this one and first made her a rapist and then a Nazis, I was uh... Not exactly stoked. But that's a personal thing, and I try to, at least partially, put that aside and review on things like technical aspect. And in that Avenue, _Crimes of Grindelwald_ is an **abysmal** failure. This is not the outright worst film of the year, but it was definitely the worst one I've seen in cinemas for a long damn time. _Final rating:\\u2605\\u00bd: - Boring/disappointing. Avoid where possible._\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmas-joined\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2401,\n        \"samples\": [\n          \"safe feel \\r\\n\\r\\n Bond 23 007 to literally come the dead steal hard drive make M Dench look bad time face past come home blood thirsty view \\r\\n\\r\\n be sure fire fact in cinema dispute of James Bond film bondphile agree corner of the spectrum come argument say bond film be gritty fun sex action fantastical stunt etc etc etc fine of course peccadillo prefer in bond movie live in different time the world change Bond the ultimate Bond want be 21st Century Bond new era of 007 be make Skyfall the bolder braver mark the 50th anniversary blend the old the new achieve brilliant result \\r\\n\\r\\n Skyfall allow to bathe in nostalgia whilst force to re- evaluate in term of beloved super secret agent of the great thing Bond be be bubble current of time importance delicately perch of James Bond shoulder M etc outdate be the future in need of operative organisation Director Mendes team of the easy option clearly available to to answer the question instead build film Bond M character embrace the tradition of the series hit hard in head heart \\r\\n\\r\\n the plot of Skyfall write be simple absolutely nail be straight true to Hollywood convention fill the simple plot be series of Bondian delight thrill spill emotionally splinter kill the stunning pre credits sequence see Bond traverse the rooftop of Istanbul motorcycle fight of speeding train to find expendable lead to Daniel Kleinman title credit sequence be fill ominous portent of death blood in turn back the wonderfully Bondian of old title song warble Adele clear point Bond movie be nod to traditional value whilst promise to deliver emotional pain prove \\r\\n\\r\\n wash bond enter the fray convince dishevel unshaven unfit tough bastard drink hard stare scorpion be soon know be in wonderful physical shape loyal to surrogate mother sure ah the adversary the scene villain to finally Craig bond to fret Javier Bardem perfect Silva cyber terrorist shock of blonde hair nasty dental trick devilish sexiness unnerve interrogation scene to bond cheekily open wink wink possibility be sexual tension in the film steamy shower scene the ongoing banter Naomie Harris excellent Eve positively fizz smirk innuendo \\r\\n\\r\\n ultimately come to the love man woman the kind be different to the type underpin Bond movie bond kill be kill M marvellous to director able to Judi Dench the direction deserve Bond in Craig magnetic gritty hand respond in kind to deliver half hour good in the 50 year of Bond film know turf be Bond turf time be turf little story come seep bond get to exorcise demon whilst kick considerable ass ready bondphile the emotional wallop see in the good bond movie of old \\r\\n\\r\\n the bondian trapping exotic locale gorgeous woman speed vehicle fight stupendous stunt bizarre lair ball machismo funny comment review Quantum of Solace pretty ace action film bondian the truth of the matter be Bond need to degree of fun matter grim gritty the story line be thankfully Skyfall be blast Craig surely convince the stubborn of dissenter good bond be have the confidence skill to lace Bond macho broody instinct desert dry wit shrug of the shoulder nonchalance of the camera the tech credit high Deakins prove to be of the ace in the pack capturing of vista be neon city scape mountainous valley eye delight colour tone beautiful promise day golden brown like Deakins \\r\\n\\r\\n the masterpiece gazillion of hope flaw new Q bit geeky safe finale lack substantial battle the villain remain simple in plot Bond birthday the birthday boy proud the maker new era Bond sure definitely be bad thing know past know future doubt know the 9/10\",\n          \"like the ending give low rating the movie ok keep interested lot of drug use make stupid stuff\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv('/content/ratings_model.csv')\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "157d3f1a-717d-456e-acbb-16a2f828e7fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "157d3f1a-717d-456e-acbb-16a2f828e7fd",
        "outputId": "e2ddd8de-9017-485e-bd1d-cbb88a0ee5f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['rating'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6ecfc8bd-1be3-4b56-8127-070286e6eb39",
      "metadata": {
        "id": "6ecfc8bd-1be3-4b56-8127-070286e6eb39"
      },
      "outputs": [],
      "source": [
        "X = df['review'].values\n",
        "y= df['target'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "69893c19-e72c-4ad2-bb9b-945cb963d8ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69893c19-e72c-4ad2-bb9b-945cb963d8ea",
        "outputId": "53946ba0-e9d5-4a42-bff3-0633a4ab8f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1224\n",
              "0    1195\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "y = pd.Series(encoder.fit_transform(y))\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "XEvxvhTt6hD1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEvxvhTt6hD1",
        "outputId": "60b9638e-a6db-46c3-da5f-73ae84b519af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Convert to Dataset object\n",
        "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "DcCdtEvY6otC",
      "metadata": {
        "id": "DcCdtEvY6otC"
      },
      "outputs": [],
      "source": [
        "# shuffling the data once\n",
        "ds = ds.shuffle(buffer_size=len(ds), reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Jjbn7dnj6Xdy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjbn7dnj6Xdy",
        "outputId": "821717a6-fdef-43ba-b3ee-bfe12a3ffdc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 1693 samples as training data\n",
            "Use 483 samples as validation data\n",
            "The remaining 243 samples will be used as test data.\n"
          ]
        }
      ],
      "source": [
        "# Determing how many samples for each split\n",
        "# Calculate the number of samples for training\n",
        "split_train = 0.7\n",
        "n_train_samples =  int(len(ds) * split_train)\n",
        "print(f\"Use {n_train_samples} samples as training data\")\n",
        "# Calculate the number of samples for validation\n",
        "split_val = 0.2\n",
        "n_val_samples = int(len(ds) * split_val)\n",
        "print(f\"Use {n_val_samples} samples as validation data\")\n",
        "# Test size is remainder\n",
        "split_test = 1 - (split_train + split_val)\n",
        "print(f\"The remaining {len(ds)- (n_train_samples+n_val_samples)} samples will be used as test data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f3LDd1sO577O",
      "metadata": {
        "id": "f3LDd1sO577O"
      },
      "outputs": [],
      "source": [
        "# Use .take to slice out the number of samples for training\n",
        "train_ds = ds.take(n_train_samples)\n",
        "# Skipover the training batches\n",
        "val_ds = ds.skip(n_train_samples)\n",
        "# Take .take to slice out the correct number of samples for validation\n",
        "val_ds = val_ds.take(n_val_samples)\n",
        "# Skip over all of the training + validation samples, the rest remain as samples for testing\n",
        "test_ds = ds.skip(n_train_samples + n_val_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9xxcHQBF62N4",
      "metadata": {
        "id": "9xxcHQBF62N4"
      },
      "outputs": [],
      "source": [
        "## Shuffling just the training data\n",
        "train_ds  = train_ds.shuffle(buffer_size = len(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "gWsf1A8t64kF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWsf1A8t64kF",
        "outputId": "5379e155-1ec8-4933-d4e1-f115b1afdf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There are 1693 training batches.\n",
            " There are 483 validation batches.\n",
            " There are 243 testing batches.\n"
          ]
        }
      ],
      "source": [
        "#  Setting the batch_size for all datasets\n",
        "BATCH_SIZE = 1\n",
        "train_ds = train_ds.batch(BATCH_SIZE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)\n",
        "# Confirm the number of batches in each\n",
        "print (f' There are {len(train_ds)} training batches.')\n",
        "print (f' There are {len(val_ds)} validation batches.')\n",
        "print (f' There are {len(test_ds)} testing batches.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test, random_state=42)"
      ],
      "metadata": {
        "id": "tQI9i2TZqjwz"
      },
      "id": "tQI9i2TZqjwz",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cLWpSKKu66WJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLWpSKKu66WJ",
        "outputId": "6b0ae197-9ffc-42b8-949e-257fc36be0a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'We have yet another movie where it is getting high praise for reasons of politics...and possibly because Jamie Lee Curtis is back...but mainly for politics.\\r\\n\\r\\nBut it was really nice seeing Jamie Lee Curtis back, and nice in the \"it doesn\\'t really feel like a Halloween movie without her in it\" kind of way.\\r\\n\\r\\nUnfortunately that isn\\'t enough to save the film, nor is the added over-the-top blood and gore that didn\\'t really need a place in the first two movies.\\r\\n\\r\\nBut...the blood and gore seemed to replace real scares (though there were a couple) as if to say, yeah, they understand that they aren\\'t making this horror movie frightening, so they might as well make it bloodier and hope that it\\'s a decent trade off for actual scares.\\r\\n\\r\\nThe main issue, however, is that it is spread thin. It\\'s like it was written in committee where everyone that there little plot be added to the film despite how difficult that would make actual story telling.\\r\\n\\r\\nThe results are so many tiny little subplots that you end up not even caring about the main plot as they try to cram them all into the same hole. You end up just not caring at all about any of it.\\r\\n\\r\\nAnd then the characters shoved into the movie to accommodate the extra plot lines are just as thin and under-developed that it\\'s really hard to care about what happens to them as well.\\r\\n\\r\\nIn the end there is so much going on that it never really focuses enough on anything to keep the audience emotionally invested and really you end up only caring about Jamie because she won you over in the first two good films and that kind of holds you just enough to actually finish a film.\\r\\n\\r\\nIf she weren\\'t cast in it, even her character would be hard to relate to in any way.\\r\\n\\r\\nIt makes you want to take the director by the collar and yell \"focus!\" with the hopes that it would drop all the unnecessary story lines and just deal with what matters.\\r\\n\\r\\nBut, you know, there are the political signaling, and for a lot of people that matters more than story telling.\\r\\n\\r\\nFor everyone else, there is about 15 minutes, maybe, of actual focused plot and the rest is all tangential.'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# Data Inspection\n",
        "\n",
        "example_X, example_y= train_ds.take(1).get_single_element()\n",
        "print(example_X)\n",
        "print(example_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "RzvXxfbE7BdK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzvXxfbE7BdK",
        "outputId": "577ab00c-f3d0-4369-e92c-c3cd31dd6017"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=string, numpy=\n",
              "array([b\"A kid is getting other kids to play poker online. The head of the university doesn't like it and threaten to throw him out. The kid (Justin Timberlake) takes all his money and play some poker, hoping that he will win and his future secure. Well, you guessed it, he loses everything. But, not because he is bad or anything, no, there is this guy called Ivan (Ben Affleck) who runs these online casinos, and who cheats the poor young kids.\\r\\n\\r\\nNow there is only one sensible thing to do, which is to go to Costa Rica and confront the bad guy with his scheme. Thats exactly what I would do. Well, nah, not really, but I hope you see where I am going with this. He arrives in Costa Rica, and soon finds himself at the deep end of the pool, hunted by Ivan, some dude named Herrera and the FBI... of course.\\r\\n\\r\\nThe plot is idiotic, as you might have guessed. It makes no sense, and the poor actors don't know how to act. And honestly, I don't blame them, they don't understand the manuscript either. I looked for a little light in the darkness, and I think I found it... the  photography. There are some beautiful images in this movie, worthy of a James Bond movie, and you know what, the plot matches the Bond movies of late pretty well too. Yeah, I am not a big Bond fan either.\\r\\n\\r\\n_Last words... it's not worth it. Ben Affleck is an overrated actor, not worth your time. Mr. Timberlake should just have stopped after The Social Network, and he would have stopped on top. This movie... don't waste your time on it. If you like poker and want to see a nice poker movie, watch Rounders instead, or even 21._\"],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Get just the text from ds_train\n",
        "ds_texts = train_ds.map(lambda x, y: x)\n",
        "# Preview the text\n",
        "ds_texts.take(1).get_single_element()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "clQgN55w7EKC",
      "metadata": {
        "id": "clQgN55w7EKC"
      },
      "outputs": [],
      "source": [
        "# Text vectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "TWf3dbyb7KLm",
      "metadata": {
        "id": "TWf3dbyb7KLm"
      },
      "outputs": [],
      "source": [
        "# Create the TextVectorization layer\n",
        "count_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    output_mode=\"count\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "afVaKFrK7K6R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afVaKFrK7K6R",
        "outputId": "7377b35b-52e9-4be7-a7b0-6a7d30601421"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Before training, only contains the out of vocab token ([UNK])\n",
        "count_vectorizer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "rlu3EFRy7Nco",
      "metadata": {
        "id": "rlu3EFRy7Nco"
      },
      "outputs": [],
      "source": [
        "# Fit the layer on the training texts\n",
        "count_vectorizer.adapt(ds_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9A2OVIj07PgF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A2OVIj07PgF",
        "outputId": "dfabc82f-509a-4d91-d409-3f6099dd7391"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 24922, ['[UNK]', 'the', 'and', 'a', 'of', 'to'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Getting list of vocab\n",
        "vocab = count_vectorizer.get_vocabulary()\n",
        "# Exploring list of vocab\n",
        "type(vocab), len(vocab), vocab[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1tSliVOI7RWi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tSliVOI7RWi",
        "outputId": "9fe168ac-36aa-4cf9-cd34-28dd0ee74da1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 24922), dtype=float32, numpy=array([[0., 2., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# The first value will be the count of all of the words not in the vocobulary\n",
        "counts= count_vectorizer(['python python python python is the most amazing thing in the world for data science!'])\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "lV5eRsQy7UZE",
      "metadata": {
        "id": "lV5eRsQy7UZE"
      },
      "outputs": [],
      "source": [
        "# TFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "lsIrHDQL7aQj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsIrHDQL7aQj",
        "outputId": "4bb81c74-0fbf-4a69-9698-63baa78ec5ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24922"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Create Text Vectorization Layer\n",
        "tfidf_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    output_mode=\"tf_idf\",\n",
        ")\n",
        "# Build the vectorizer vocabulary\n",
        "tfidf_vectorizer.adapt(ds_texts)\n",
        "# Confrim vocabulary size\n",
        "tfidf_vectorizer.vocabulary_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "lyIGfEW37ccg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyIGfEW37ccg",
        "outputId": "fd461aaa-7dd4-4e3f-e33f-c2fdc2b4a9e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 24922), dtype=float32, numpy=\n",
              "array([[0.       , 1.4785116, 0.       , ..., 0.       , 0.       ,\n",
              "        0.       ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# The first value will be the score of all of the words not in the vocobulary\n",
        "tfidf= tfidf_vectorizer(['python python python python is the most amazing thing in the world for data science!'])\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "neugj4DY7gnh",
      "metadata": {
        "id": "neugj4DY7gnh"
      },
      "outputs": [],
      "source": [
        "# Sequence Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "zT5Annli7jrC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT5Annli7jrC",
        "outputId": "fd84aeb3-bb9c-4641-8f90-1a7a31ba2cbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24923"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Create text Vectorization layer\n",
        "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=30\n",
        ")\n",
        "sequence_vectorizer.adapt(ds_texts)\n",
        "sequence_vectorizer.vocabulary_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ur8RP87k7kTx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur8RP87k7kTx",
        "outputId": "6cf912a5-313f-4ee2-92d5-a2febb439b5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 30), dtype=int64, numpy=\n",
              "array([[16469, 16469, 16469, 16469,     7,     2,    74,   392,   148,\n",
              "            9,     2,   143,    16, 22305,   952,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Obtain the sequence of sample text with the sequence_vectorizer\n",
        "sequence= sequence_vectorizer(['python python python python is the most amazing thing in the world for data science!'])\n",
        "sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4pPE_eY07oj7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pPE_eY07oj7",
        "outputId": "6b82c72c-8743-444e-df58-4c7d138079a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '',\n",
              " 1: '[UNK]',\n",
              " 2: 'the',\n",
              " 3: 'and',\n",
              " 4: 'a',\n",
              " 5: 'of',\n",
              " 6: 'to',\n",
              " 7: 'is',\n",
              " 8: 'it',\n",
              " 9: 'in',\n",
              " 10: 'that',\n",
              " 11: 'i',\n",
              " 12: 'this',\n",
              " 13: 'but',\n",
              " 14: 'was',\n",
              " 15: 'with',\n",
              " 16: 'for',\n",
              " 17: 'as',\n",
              " 18: 'movie',\n",
              " 19: 'film',\n",
              " 20: 'not',\n",
              " 21: 'are',\n",
              " 22: 'its',\n",
              " 23: 'on',\n",
              " 24: 'be',\n",
              " 25: 'you',\n",
              " 26: 'one',\n",
              " 27: 'have',\n",
              " 28: 'his',\n",
              " 29: 'an',\n",
              " 30: 'so',\n",
              " 31: 'all',\n",
              " 32: 'like',\n",
              " 33: 'from',\n",
              " 34: 'he',\n",
              " 35: 'at',\n",
              " 36: 'by',\n",
              " 37: 'just',\n",
              " 38: 'they',\n",
              " 39: 'if',\n",
              " 40: 'about',\n",
              " 41: 'or',\n",
              " 42: 'what',\n",
              " 43: 'more',\n",
              " 44: 'story',\n",
              " 45: 'has',\n",
              " 46: 'there',\n",
              " 47: 'some',\n",
              " 48: 'even',\n",
              " 49: 'who',\n",
              " 50: 'my',\n",
              " 51: 'good',\n",
              " 52: 'really',\n",
              " 53: 'me',\n",
              " 54: 'out',\n",
              " 55: 'very',\n",
              " 56: 'time',\n",
              " 57: 'when',\n",
              " 58: 'no',\n",
              " 59: 'which',\n",
              " 60: 'we',\n",
              " 61: 'only',\n",
              " 62: 'well',\n",
              " 63: 'their',\n",
              " 64: 'had',\n",
              " 65: 'much',\n",
              " 66: 'can',\n",
              " 67: 'up',\n",
              " 68: 'than',\n",
              " 69: 'would',\n",
              " 70: 'also',\n",
              " 71: 'because',\n",
              " 72: 'great',\n",
              " 73: 'way',\n",
              " 74: 'most',\n",
              " 75: 'do',\n",
              " 76: 'into',\n",
              " 77: 'her',\n",
              " 78: 'characters',\n",
              " 79: 'will',\n",
              " 80: 'were',\n",
              " 81: 'how',\n",
              " 82: 'first',\n",
              " 83: 'films',\n",
              " 84: 'best',\n",
              " 85: 'movies',\n",
              " 86: 'been',\n",
              " 87: 'character',\n",
              " 88: 'watch',\n",
              " 89: 'action',\n",
              " 90: 'other',\n",
              " 91: 'see',\n",
              " 92: 'people',\n",
              " 93: 'where',\n",
              " 94: 'them',\n",
              " 95: 'two',\n",
              " 96: 'get',\n",
              " 97: 'then',\n",
              " 98: 'being',\n",
              " 99: 'did',\n",
              " 100: 'know',\n",
              " 101: 'too',\n",
              " 102: 'dont',\n",
              " 103: 'any',\n",
              " 104: 'she',\n",
              " 105: 'make',\n",
              " 106: 'him',\n",
              " 107: 'bad',\n",
              " 108: 'after',\n",
              " 109: 'still',\n",
              " 110: 'made',\n",
              " 111: 'plot',\n",
              " 112: 'never',\n",
              " 113: 'going',\n",
              " 114: 'could',\n",
              " 115: 'end',\n",
              " 116: 'does',\n",
              " 117: 'every',\n",
              " 118: 'think',\n",
              " 119: 'actually',\n",
              " 120: 'here',\n",
              " 121: 'these',\n",
              " 122: 'cast',\n",
              " 123: 'those',\n",
              " 124: 'work',\n",
              " 125: 'many',\n",
              " 126: 'something',\n",
              " 127: 'say',\n",
              " 128: 'us',\n",
              " 129: 'while',\n",
              " 130: 'now',\n",
              " 131: 'lot',\n",
              " 132: 'seen',\n",
              " 133: 'things',\n",
              " 134: 'love',\n",
              " 135: 'though',\n",
              " 136: 'life',\n",
              " 137: 'little',\n",
              " 138: 'im',\n",
              " 139: 'better',\n",
              " 140: 'scenes',\n",
              " 141: 'its',\n",
              " 142: 'feel',\n",
              " 143: 'world',\n",
              " 144: 'why',\n",
              " 145: 'over',\n",
              " 146: 'same',\n",
              " 147: 'everything',\n",
              " 148: 'thing',\n",
              " 149: 'new',\n",
              " 150: 'another',\n",
              " 151: 'your',\n",
              " 152: 'didnt',\n",
              " 153: 'such',\n",
              " 154: 'off',\n",
              " 155: 'makes',\n",
              " 156: 'ever',\n",
              " 157: 'doesnt',\n",
              " 158: 'real',\n",
              " 159: 'go',\n",
              " 160: 'enough',\n",
              " 161: 'point',\n",
              " 162: 'however',\n",
              " 163: 'again',\n",
              " 164: 'through',\n",
              " 165: 'right',\n",
              " 166: 'should',\n",
              " 167: 'both',\n",
              " 168: 'pretty',\n",
              " 169: 'quite',\n",
              " 170: 'nothing',\n",
              " 171: 'far',\n",
              " 172: 'original',\n",
              " 173: 'scene',\n",
              " 174: 'few',\n",
              " 175: 'thats',\n",
              " 176: 'watching',\n",
              " 177: 'fun',\n",
              " 178: 'before',\n",
              " 179: 'man',\n",
              " 180: 'part',\n",
              " 181: 'years',\n",
              " 182: 'kind',\n",
              " 183: 'back',\n",
              " 184: 'want',\n",
              " 185: 'long',\n",
              " 186: 'without',\n",
              " 187: 'final',\n",
              " 188: 'especially',\n",
              " 189: 'big',\n",
              " 190: 'director',\n",
              " 191: 'acting',\n",
              " 192: 'around',\n",
              " 193: 'yet',\n",
              " 194: 'theres',\n",
              " 195: 'performance',\n",
              " 196: 'our',\n",
              " 197: 'almost',\n",
              " 198: 'since',\n",
              " 199: 'least',\n",
              " 200: 'between',\n",
              " 201: 'actors',\n",
              " 202: 'horror',\n",
              " 203: 'always',\n",
              " 204: 'bit',\n",
              " 205: 'might',\n",
              " 206: 'down',\n",
              " 207: 'am',\n",
              " 208: 'audience',\n",
              " 209: 'look',\n",
              " 210: 'take',\n",
              " 211: 'cant',\n",
              " 212: 'own',\n",
              " 213: 'fact',\n",
              " 214: 'find',\n",
              " 215: 'different',\n",
              " 216: 'thought',\n",
              " 217: 'anything',\n",
              " 218: 'last',\n",
              " 219: 'whole',\n",
              " 220: 'comes',\n",
              " 221: 'making',\n",
              " 222: 'give',\n",
              " 223: 'effects',\n",
              " 224: 'isnt',\n",
              " 225: 'got',\n",
              " 226: 'away',\n",
              " 227: 'script',\n",
              " 228: 'role',\n",
              " 229: 'hes',\n",
              " 230: 'everyone',\n",
              " 231: 'old',\n",
              " 232: 'excellent',\n",
              " 233: 'performances',\n",
              " 234: 'full',\n",
              " 235: 'course',\n",
              " 236: 'perfect',\n",
              " 237: 'come',\n",
              " 238: 'probably',\n",
              " 239: 'music',\n",
              " 240: 'ive',\n",
              " 241: 'felt',\n",
              " 242: 'family',\n",
              " 243: 'sense',\n",
              " 244: 'sure',\n",
              " 245: 'year',\n",
              " 246: 'each',\n",
              " 247: '',\n",
              " 248: 'done',\n",
              " 249: 'place',\n",
              " 250: 'moments',\n",
              " 251: 'seems',\n",
              " 252: 'actor',\n",
              " 253: 'review',\n",
              " 254: 'main',\n",
              " 255: 'absolutely',\n",
              " 256: 'minutes',\n",
              " 257: 'cinematography',\n",
              " 258: 'set',\n",
              " 259: 'rather',\n",
              " 260: 'having',\n",
              " 261: 'said',\n",
              " 262: 'definitely',\n",
              " 263: 'takes',\n",
              " 264: 'job',\n",
              " 265: 'funny',\n",
              " 266: 'fan',\n",
              " 267: 'times',\n",
              " 268: 'dark',\n",
              " 269: 'score',\n",
              " 270: 'less',\n",
              " 271: 'entire',\n",
              " 272: 'enjoy',\n",
              " 273: 'second',\n",
              " 274: 'simply',\n",
              " 275: 'once',\n",
              " 276: 'star',\n",
              " 277: 'given',\n",
              " 278: 'poor',\n",
              " 279: 'may',\n",
              " 280: 'instead',\n",
              " 281: 'young',\n",
              " 282: 'comedy',\n",
              " 283: 'understand',\n",
              " 284: 'start',\n",
              " 285: 'mind',\n",
              " 286: 'high',\n",
              " 287: 'feels',\n",
              " 288: 'based',\n",
              " 289: 'watched',\n",
              " 290: 'someone',\n",
              " 291: 'three',\n",
              " 292: 'need',\n",
              " 293: 'itself',\n",
              " 294: 'trying',\n",
              " 295: 'top',\n",
              " 296: 'together',\n",
              " 297: 'narrative',\n",
              " 298: 'hard',\n",
              " 299: 'franchise',\n",
              " 300: 'screen',\n",
              " 301: 'worst',\n",
              " 302: 'throughout',\n",
              " 303: 'ending',\n",
              " 304: 'reason',\n",
              " 305: 'already',\n",
              " 306: 'interesting',\n",
              " 307: 'completely',\n",
              " 308: 'special',\n",
              " 309: 'show',\n",
              " 310: 'series',\n",
              " 311: 'mean',\n",
              " 312: 'goes',\n",
              " 313: 'overall',\n",
              " 314: 'liked',\n",
              " 315: 'john',\n",
              " 316: 'despite',\n",
              " 317: 'maybe',\n",
              " 318: 'hollywood',\n",
              " 319: 'wrong',\n",
              " 320: 'true',\n",
              " 321: 'sort',\n",
              " 322: 'must',\n",
              " 323: 'single',\n",
              " 324: 'works',\n",
              " 325: 'entertaining',\n",
              " 326: 'either',\n",
              " 327: 'although',\n",
              " 328: 'left',\n",
              " 329: 'wasnt',\n",
              " 330: 'war',\n",
              " 331: 'put',\n",
              " 332: 'found',\n",
              " 333: 'cgi',\n",
              " 334: 'gets',\n",
              " 335: 'fantastic',\n",
              " 336: 'cinema',\n",
              " 337: 'rating',\n",
              " 338: 'piece',\n",
              " 339: 'black',\n",
              " 340: 'truly',\n",
              " 341: 'quality',\n",
              " 342: 'guy',\n",
              " 343: 'else',\n",
              " 344: 'loved',\n",
              " 345: 'bond',\n",
              " 346: 'appeal',\n",
              " 347: 'due',\n",
              " 348: 'until',\n",
              " 349: 'shot',\n",
              " 350: 'half',\n",
              " 351: 'genre',\n",
              " 352: 'during',\n",
              " 353: 'beautiful',\n",
              " 354: 'sequel',\n",
              " 355: 'screenplay',\n",
              " 356: 'book',\n",
              " 357: 'written',\n",
              " 358: 'saw',\n",
              " 359: 'rest',\n",
              " 360: 'idea',\n",
              " 361: 'day',\n",
              " 362: 'honestly',\n",
              " 363: 'care',\n",
              " 364: 'unfortunately',\n",
              " 365: 'possible',\n",
              " 366: 'human',\n",
              " 367: 'couple',\n",
              " 368: 'brilliant',\n",
              " 369: 'seeing',\n",
              " 370: 'play',\n",
              " 371: 'batman',\n",
              " 372: 'worth',\n",
              " 373: 'reviews',\n",
              " 374: 'favorite',\n",
              " 375: 'cool',\n",
              " 376: 'use',\n",
              " 377: 'played',\n",
              " 378: 'able',\n",
              " 379: '2',\n",
              " 380: 'yes',\n",
              " 381: 'totally',\n",
              " 382: 'looks',\n",
              " 383: 'doing',\n",
              " 384: 'act',\n",
              " 385: 'youre',\n",
              " 386: 'try',\n",
              " 387: 'sequences',\n",
              " 388: 'past',\n",
              " 389: 'fight',\n",
              " 390: 'fans',\n",
              " 391: 'boring',\n",
              " 392: 'amazing',\n",
              " 393: 'help',\n",
              " 394: 'anyone',\n",
              " 395: 'stars',\n",
              " 396: 'gives',\n",
              " 397: 'finally',\n",
              " 398: 'production',\n",
              " 399: 'himself',\n",
              " 400: 'dont',\n",
              " 401: 'believe',\n",
              " 402: 'remember',\n",
              " 403: 'looking',\n",
              " 404: 'dialogue',\n",
              " 405: 'wont',\n",
              " 406: 'wanted',\n",
              " 407: 'against',\n",
              " 408: 'experience',\n",
              " 409: 'enjoyed',\n",
              " 410: 'days',\n",
              " 411: 'writing',\n",
              " 412: 'version',\n",
              " 413: 'short',\n",
              " 414: 'political',\n",
              " 415: 'plays',\n",
              " 416: 'moment',\n",
              " 417: 'michael',\n",
              " 418: 'case',\n",
              " 419: 'came',\n",
              " 420: 'tell',\n",
              " 421: 'strong',\n",
              " 422: 'lead',\n",
              " 423: 'death',\n",
              " 424: 'worse',\n",
              " 425: 'shows',\n",
              " 426: 'read',\n",
              " 427: 'others',\n",
              " 428: 'james',\n",
              " 429: 'guess',\n",
              " 430: 'emotional',\n",
              " 431: 'decent',\n",
              " 432: 'stupid',\n",
              " 433: 'remake',\n",
              " 434: 'product',\n",
              " 435: 'later',\n",
              " 436: 'directed',\n",
              " 437: 'become',\n",
              " 438: 'style',\n",
              " 439: 'seem',\n",
              " 440: 'mostly',\n",
              " 441: 'home',\n",
              " 442: 'heart',\n",
              " 443: 'feeling',\n",
              " 444: 'exactly',\n",
              " 445: 'theres',\n",
              " 446: 'side',\n",
              " 447: 'perhaps',\n",
              " 448: 'next',\n",
              " 449: 'message',\n",
              " 450: 'keep',\n",
              " 451: 'supposed',\n",
              " 452: 'starts',\n",
              " 453: 'person',\n",
              " 454: 'nice',\n",
              " 455: 'soundtrack',\n",
              " 456: 'father',\n",
              " 457: 'becomes',\n",
              " 458: 'american',\n",
              " 459: 'recommend',\n",
              " 460: 'mother',\n",
              " 461: 'events',\n",
              " 462: 'coming',\n",
              " 463: 'clearly',\n",
              " 464: 'women',\n",
              " 465: 'hope',\n",
              " 466: 'giving',\n",
              " 467: 'easily',\n",
              " 468: 'used',\n",
              " 469: 'name',\n",
              " 470: 'editing',\n",
              " 471: 'woman',\n",
              " 472: 'visual',\n",
              " 473: 'face',\n",
              " 474: 'expect',\n",
              " 475: 'ends',\n",
              " 476: 'classic',\n",
              " 477: 'behind',\n",
              " 478: 'money',\n",
              " 479: 'matter',\n",
              " 480: 'getting',\n",
              " 481: 'terrible',\n",
              " 482: 'simple',\n",
              " 483: 'incredibly',\n",
              " 484: 'thats',\n",
              " 485: 'small',\n",
              " 486: 'marvel',\n",
              " 487: 'hours',\n",
              " 488: 'history',\n",
              " 489: 'follow',\n",
              " 490: 'delivers',\n",
              " 491: 'seriously',\n",
              " 492: 'lost',\n",
              " 493: 'eyes',\n",
              " 494: 'doesnt',\n",
              " 495: 'went',\n",
              " 496: 'took',\n",
              " 497: 'entertainment',\n",
              " 498: 'tom',\n",
              " 499: 'third',\n",
              " 500: 'sequence',\n",
              " 501: 'rating',\n",
              " 502: 'hand',\n",
              " 503: 'guys',\n",
              " 504: 'finished',\n",
              " 505: 'expected',\n",
              " 506: 'certainly',\n",
              " 507: 'actual',\n",
              " 508: 'level',\n",
              " 509: 'hate',\n",
              " 510: 'girl',\n",
              " 511: 'extremely',\n",
              " 512: 'opening',\n",
              " 513: 'obviously',\n",
              " 514: 'modern',\n",
              " 515: 'line',\n",
              " 516: 'beginning',\n",
              " 517: 'avoid',\n",
              " 518: 'turn',\n",
              " 519: 'ones',\n",
              " 520: 'gave',\n",
              " 521: 'flick',\n",
              " 522: 'blood',\n",
              " 523: '3',\n",
              " 524: 'previous',\n",
              " 525: 'picture',\n",
              " 526: 'perfectly',\n",
              " 527: 'literally',\n",
              " 528: 'fine',\n",
              " 529: 'voice',\n",
              " 530: 'kids',\n",
              " 531: 'close',\n",
              " 532: 'along',\n",
              " 533: 'viewers',\n",
              " 534: 'viewer',\n",
              " 535: 'parts',\n",
              " 536: 'let',\n",
              " 537: 'huge',\n",
              " 538: 'turns',\n",
              " 539: 'myself',\n",
              " 540: 'men',\n",
              " 541: 'masterpiece',\n",
              " 542: 'impressive',\n",
              " 543: 'hero',\n",
              " 544: 'expecting',\n",
              " 545: 'drama',\n",
              " 546: 'direction',\n",
              " 547: '',\n",
              " 548: 'wants',\n",
              " 549: 'several',\n",
              " 550: 'okay',\n",
              " 551: 'cannot',\n",
              " 552: '10',\n",
              " 553: 'universe',\n",
              " 554: 'stuff',\n",
              " 555: 'particularly',\n",
              " 556: 'knows',\n",
              " 557: 'hour',\n",
              " 558: 'entirely',\n",
              " 559: 'early',\n",
              " 560: 'attention',\n",
              " 561: 'white',\n",
              " 562: 'usually',\n",
              " 563: 'unique',\n",
              " 564: 'type',\n",
              " 565: 'thinking',\n",
              " 566: 'silly',\n",
              " 567: 'serious',\n",
              " 568: 'robert',\n",
              " 569: 'leave',\n",
              " 570: 'lack',\n",
              " 571: 'house',\n",
              " 572: 'david',\n",
              " 573: 'comic',\n",
              " 574: 'wars',\n",
              " 575: 'saying',\n",
              " 576: 'means',\n",
              " 577: 'incredible',\n",
              " 578: 'id',\n",
              " 579: 'humor',\n",
              " 580: 'head',\n",
              " 581: 'children',\n",
              " 582: 'called',\n",
              " 583: 'words',\n",
              " 584: 'within',\n",
              " 585: 'save',\n",
              " 586: 'roles',\n",
              " 587: 'major',\n",
              " 588: 'future',\n",
              " 589: 'bring',\n",
              " 590: 'awesome',\n",
              " 591: 'animation',\n",
              " 592: '1',\n",
              " 593: 'under',\n",
              " 594: 'told',\n",
              " 595: 'themselves',\n",
              " 596: 'taking',\n",
              " 597: 'superb',\n",
              " 598: 'sometimes',\n",
              " 599: 'run',\n",
              " 600: 'predictable',\n",
              " 601: 'including',\n",
              " 602: 'hit',\n",
              " 603: 'female',\n",
              " 604: 'camera',\n",
              " 605: 'villain',\n",
              " 606: 'towards',\n",
              " 607: 'surprise',\n",
              " 608: 'superhero',\n",
              " 609: 'slow',\n",
              " 610: 'seemed',\n",
              " 611: 'outstanding',\n",
              " 612: 'important',\n",
              " 613: 'hell',\n",
              " 614: 'couldnt',\n",
              " 615: 'city',\n",
              " 616: 'art',\n",
              " 617: 'across',\n",
              " 618: 'tale',\n",
              " 619: 'sets',\n",
              " 620: 'reality',\n",
              " 621: 'points',\n",
              " 622: 'order',\n",
              " 623: 'opinion',\n",
              " 624: 'oh',\n",
              " 625: 'needs',\n",
              " 626: 'live',\n",
              " 627: 'indeed',\n",
              " 628: 'ill',\n",
              " 629: 'force',\n",
              " 630: 'cinematic',\n",
              " 631: 'above',\n",
              " 632: 'started',\n",
              " 633: 'mystery',\n",
              " 634: 'material',\n",
              " 635: 'mark',\n",
              " 636: 'except',\n",
              " 637: 'earth',\n",
              " 638: 'doubt',\n",
              " 639: 'clear',\n",
              " 640: 'change',\n",
              " 641: 'budget',\n",
              " 642: 'age',\n",
              " 643: 'adventure',\n",
              " 644: 'title',\n",
              " 645: 'son',\n",
              " 646: 'powerful',\n",
              " 647: 'please',\n",
              " 648: 'often',\n",
              " 649: 'im',\n",
              " 650: 'god',\n",
              " 651: 'game',\n",
              " 652: 'design',\n",
              " 653: 'beyond',\n",
              " 654: 'wonderful',\n",
              " 655: 'violence',\n",
              " 656: 'turned',\n",
              " 657: 'somewhat',\n",
              " 658: 'reading',\n",
              " 659: 'problem',\n",
              " 660: 'filled',\n",
              " 661: 'example',\n",
              " 662: 'cut',\n",
              " 663: 'theyre',\n",
              " 664: 'super',\n",
              " 665: 'stunning',\n",
              " 666: 'stop',\n",
              " 667: 'sound',\n",
              " 668: 'relationship',\n",
              " 669: 'mention',\n",
              " 670: 'looked',\n",
              " 671: 'latter',\n",
              " 672: 'critics',\n",
              " 673: 'brings',\n",
              " 674: 'attempt',\n",
              " 675: 'wonder',\n",
              " 676: 'thriller',\n",
              " 677: 'strange',\n",
              " 678: 'ridiculous',\n",
              " 679: 'positive',\n",
              " 680: 'low',\n",
              " 681: 'knew',\n",
              " 682: 'group',\n",
              " 683: 'disappointed',\n",
              " 684: 'deserves',\n",
              " 685: 'deep',\n",
              " 686: 'career',\n",
              " 687: 'absolute',\n",
              " 688: 'tried',\n",
              " 689: 'stories',\n",
              " 690: 'release',\n",
              " 691: 'light',\n",
              " 692: 'laugh',\n",
              " 693: 'issue',\n",
              " 694: 'elements',\n",
              " 695: 'easy',\n",
              " 696: 'dumb',\n",
              " 697: 'call',\n",
              " 698: 'anyway',\n",
              " 699: 'add',\n",
              " 700: 'twist',\n",
              " 701: 'school',\n",
              " 702: 'hilarious',\n",
              " 703: 'happens',\n",
              " 704: 'deliver',\n",
              " 705: 'daughter',\n",
              " 706: 'biggest',\n",
              " 707: 'western',\n",
              " 708: 'waste',\n",
              " 709: 'terrific',\n",
              " 710: 'team',\n",
              " 711: 'similar',\n",
              " 712: 'sex',\n",
              " 713: 'runtime',\n",
              " 714: 'premise',\n",
              " 715: 'personal',\n",
              " 716: 'leads',\n",
              " 717: 'happen',\n",
              " 718: 'gone',\n",
              " 719: 'complete',\n",
              " 720: 'amount',\n",
              " 721: 'addition',\n",
              " 722: '4',\n",
              " 723: 'write',\n",
              " 724: 'word',\n",
              " 725: 'wife',\n",
              " 726: 'tension',\n",
              " 727: 'question',\n",
              " 728: 'playing',\n",
              " 729: 'ok',\n",
              " 730: 'night',\n",
              " 731: 'middle',\n",
              " 732: 'evil',\n",
              " 733: 'era',\n",
              " 734: 'effort',\n",
              " 735: 'ago',\n",
              " 736: 'yeah',\n",
              " 737: 'room',\n",
              " 738: 'plenty',\n",
              " 739: 'obvious',\n",
              " 740: 'genuinely',\n",
              " 741: 'forced',\n",
              " 742: 'etc',\n",
              " 743: 'dramatic',\n",
              " 744: 'didnt',\n",
              " 745: 'dead',\n",
              " 746: 'tv',\n",
              " 747: 'tries',\n",
              " 748: 'today',\n",
              " 749: 'supporting',\n",
              " 750: 'power',\n",
              " 751: 'poorly',\n",
              " 752: 'particular',\n",
              " 753: 'pacing',\n",
              " 754: 'jokes',\n",
              " 755: 'issues',\n",
              " 756: 'feature',\n",
              " 757: 'complex',\n",
              " 758: 'animated',\n",
              " 759: 'alone',\n",
              " 760: '910',\n",
              " 761: 'tone',\n",
              " 762: 'tells',\n",
              " 763: 'setting',\n",
              " 764: 'realistic',\n",
              " 765: 'number',\n",
              " 766: 'leaves',\n",
              " 767: 'known',\n",
              " 768: 'green',\n",
              " 769: 'greatest',\n",
              " 770: 'enjoyable',\n",
              " 771: 'basically',\n",
              " 772: 'whether',\n",
              " 773: 'upon',\n",
              " 774: 'theme',\n",
              " 775: 'stand',\n",
              " 776: 'spoilerfree',\n",
              " 777: 'released',\n",
              " 778: 'none',\n",
              " 779: 'lets',\n",
              " 780: 'involved',\n",
              " 781: 'created',\n",
              " 782: 'boy',\n",
              " 783: 'aspect',\n",
              " 784: 'whatever',\n",
              " 785: 'ultimately',\n",
              " 786: 'technical',\n",
              " 787: 'talk',\n",
              " 788: 'reasons',\n",
              " 789: 'lines',\n",
              " 790: 'highly',\n",
              " 791: 'happy',\n",
              " 792: 'fear',\n",
              " 793: 'favourite',\n",
              " 794: 'chris',\n",
              " 795: 'awful',\n",
              " 796: 'wouldnt',\n",
              " 797: 'worked',\n",
              " 798: 'visuals',\n",
              " 799: 'utterly',\n",
              " 800: 'situation',\n",
              " 801: 'scifi',\n",
              " 802: 'note',\n",
              " 803: 'nor',\n",
              " 804: 'lives',\n",
              " 805: 'jump',\n",
              " 806: 'isnt',\n",
              " 807: 'happened',\n",
              " 808: 'girls',\n",
              " 809: 'friends',\n",
              " 810: 'forget',\n",
              " 811: 'development',\n",
              " 812: 'create',\n",
              " 813: 'certain',\n",
              " 814: 'car',\n",
              " 815: 'box',\n",
              " 816: 'battle',\n",
              " 817: 'worthy',\n",
              " 818: 'whilst',\n",
              " 819: 'view',\n",
              " 820: 'train',\n",
              " 821: 'thus',\n",
              " 822: 'space',\n",
              " 823: 'oscar',\n",
              " 824: 'living',\n",
              " 825: 'humour',\n",
              " 826: 'failed',\n",
              " 827: 'emotionally',\n",
              " 828: 'captain',\n",
              " 829: 'cant',\n",
              " 830: 'writers',\n",
              " 831: 'working',\n",
              " 832: 'usual',\n",
              " 833: 'twists',\n",
              " 834: 'theater',\n",
              " 835: 'shes',\n",
              " 836: 'impossible',\n",
              " 837: 'historical',\n",
              " 838: 'fully',\n",
              " 839: 'fresh',\n",
              " 840: 'following',\n",
              " 841: 'fantasy',\n",
              " 842: 'expectations',\n",
              " 843: 'die',\n",
              " 844: 'crime',\n",
              " 845: 'christopher',\n",
              " 846: 'america',\n",
              " 847: 'alien',\n",
              " 848: 'weird',\n",
              " 849: 'soon',\n",
              " 850: 'sam',\n",
              " 851: 'peter',\n",
              " 852: 'nolan',\n",
              " 853: 'journey',\n",
              " 854: 'form',\n",
              " 855: 'focus',\n",
              " 856: 'dull',\n",
              " 857: 'disney',\n",
              " 858: 'directors',\n",
              " 859: 'crap',\n",
              " 860: 'conclusion',\n",
              " 861: 'bloody',\n",
              " 862: 'whose',\n",
              " 863: 'wait',\n",
              " 864: 'value',\n",
              " 865: 'trilogy',\n",
              " 866: 'themes',\n",
              " 867: 'praise',\n",
              " 868: 'period',\n",
              " 869: 'lots',\n",
              " 870: 'language',\n",
              " 871: 'kid',\n",
              " 872: 'interest',\n",
              " 873: 'imagine',\n",
              " 874: 'finds',\n",
              " 875: 'decade',\n",
              " 876: 'british',\n",
              " 877: 'wrote',\n",
              " 878: 'using',\n",
              " 879: 'talking',\n",
              " 880: 'surprised',\n",
              " 881: 'success',\n",
              " 882: 'social',\n",
              " 883: 'shots',\n",
              " 884: 'problems',\n",
              " 885: 'personally',\n",
              " 886: 'open',\n",
              " 887: 'near',\n",
              " 888: 'justice',\n",
              " 889: 'heroes',\n",
              " 890: 'heard',\n",
              " 891: 'four',\n",
              " 892: 'forward',\n",
              " 893: 'figure',\n",
              " 894: 'details',\n",
              " 895: 'apart',\n",
              " 896: 'xmen',\n",
              " 897: 'wish',\n",
              " 898: 'verdict',\n",
              " 899: 'total',\n",
              " 900: 'talent',\n",
              " 901: 'quickly',\n",
              " 902: 'moving',\n",
              " 903: 'honest',\n",
              " 904: 'hes',\n",
              " 905: 'happening',\n",
              " 906: 'further',\n",
              " 907: 'follows',\n",
              " 908: 'epic',\n",
              " 909: 'decided',\n",
              " 910: 'class',\n",
              " 911: 'ben',\n",
              " 912: 'average',\n",
              " 913: 'audiences',\n",
              " 914: 'video',\n",
              " 915: 'terms',\n",
              " 916: 'taken',\n",
              " 917: 'superman',\n",
              " 918: 'storytelling',\n",
              " 919: 'somehow',\n",
              " 920: 'sad',\n",
              " 921: 'revenge',\n",
              " 922: 'recent',\n",
              " 923: 'protagonist',\n",
              " 924: 'novel',\n",
              " 925: 'mcu',\n",
              " 926: 'king',\n",
              " 927: 'killer',\n",
              " 928: 'kill',\n",
              " 929: 'horrible',\n",
              " 930: 'fair',\n",
              " 931: 'chemistry',\n",
              " 932: 'zombie',\n",
              " 933: 'state',\n",
              " 934: 'fit',\n",
              " 935: 'fast',\n",
              " 936: 'essentially',\n",
              " 937: 'english',\n",
              " 938: 'credits',\n",
              " 939: 'country',\n",
              " 940: 'control',\n",
              " 941: 'compelling',\n",
              " 942: 'child',\n",
              " 943: 'captivating',\n",
              " 944: 'brought',\n",
              " 945: 'the',\n",
              " 946: 'yourself',\n",
              " 947: 'writer',\n",
              " 948: 'villains',\n",
              " 949: 'truth',\n",
              " 950: 'technically',\n",
              " 951: 'sounds',\n",
              " 952: 'science',\n",
              " 953: 'move',\n",
              " 954: 'memorable',\n",
              " 955: 'impact',\n",
              " 956: 'general',\n",
              " 957: 'fiction',\n",
              " 958: 'disappointment',\n",
              " 959: 'disappointing',\n",
              " 960: 'bunch',\n",
              " 961: 'begins',\n",
              " 962: 'begin',\n",
              " 963: 'becoming',\n",
              " 964: 'background',\n",
              " 965: 'wick',\n",
              " 966: 'ways',\n",
              " 967: 'showing',\n",
              " 968: 'scary',\n",
              " 969: 'office',\n",
              " 970: 'murder',\n",
              " 971: 'mess',\n",
              " 972: 'killed',\n",
              " 973: 'difficult',\n",
              " 974: 'depth',\n",
              " 975: 'concept',\n",
              " 976: 'choice',\n",
              " 977: 'changed',\n",
              " 978: 'chance',\n",
              " 979: 'casting',\n",
              " 980: 'bruce',\n",
              " 981: 'boringdisappointing',\n",
              " 982: 'viewing',\n",
              " 983: 'studio',\n",
              " 984: 'sadly',\n",
              " 985: 'rating',\n",
              " 986: 'project',\n",
              " 987: 'paul',\n",
              " 988: 'minute',\n",
              " 989: 'matrix',\n",
              " 990: 'massive',\n",
              " 991: 'list',\n",
              " 992: 'late',\n",
              " 993: 'havent',\n",
              " 994: 'five',\n",
              " 995: 'fall',\n",
              " 996: 'deal',\n",
              " 997: 'dance',\n",
              " 998: 'core',\n",
              " 999: 'appreciate',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Getting list of vocab\n",
        "vocab = sequence_vectorizer.get_vocabulary()\n",
        "int_to_str = {idx: word for idx, word in enumerate(vocab)}\n",
        "int_to_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "OB88vBBr-UC1",
      "metadata": {
        "id": "OB88vBBr-UC1"
      },
      "outputs": [],
      "source": [
        "# Set up Pipeline to allow GridSearching different vectorizers\n",
        "vect_pipe = Pipeline([('vectorizer', CountVectorizer()), # This is just a placeholder\n",
        "                     ('clf',MultinomialNB())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "0JCrGJ1T-XuW",
      "metadata": {
        "id": "0JCrGJ1T-XuW"
      },
      "outputs": [],
      "source": [
        "# Define a param grid with options for the vectorizer\n",
        "param_grid = {\n",
        "    'vectorizer': [CountVectorizer(), TfidfVectorizer()],\n",
        "    'clf__alpha': [.5, 1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "40siapIe_cx6",
      "metadata": {
        "id": "40siapIe_cx6"
      },
      "outputs": [],
      "source": [
        "# Create grid search\n",
        "grid_search = GridSearchCV(vect_pipe, param_grid, cv=3, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ot8ipbZoAU2_",
      "metadata": {
        "id": "ot8ipbZoAU2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "b623deb9-9d5e-4ab6-b05d-ca562c5e057f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
              "                                       ('clf', MultinomialNB())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'clf__alpha': [0.5, 1],\n",
              "                         'vectorizer': [CountVectorizer(), TfidfVectorizer()]},\n",
              "             verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__alpha&#x27;: [0.5, 1],\n",
              "                         &#x27;vectorizer&#x27;: [CountVectorizer(), TfidfVectorizer()]},\n",
              "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                                       (&#x27;clf&#x27;, MultinomialNB())]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;clf__alpha&#x27;: [0.5, 1],\n",
              "                         &#x27;vectorizer&#x27;: [CountVectorizer(), TfidfVectorizer()]},\n",
              "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep NLP Models**"
      ],
      "metadata": {
        "id": "4-oMwG8a5Gtk"
      },
      "id": "4-oMwG8a5Gtk"
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "y = pd.Series(encoder.fit_transform(y))\n",
        "y.value_counts()"
      ],
      "metadata": {
        "id": "yf4cpaQQRc_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2d6f97-26b8-49cc-ec50-b23f79208aeb"
      },
      "id": "yf4cpaQQRc_V",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1224\n",
              "0    1195\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SgJWhbx5Iot",
        "outputId": "eb81972c-4867-4829-b5b0-56fda10a0613"
      },
      "id": "0SgJWhbx5Iot",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.shuffle(buffer_size=len(ds), reshuffle_each_iteration=False)"
      ],
      "metadata": {
        "id": "NQ8hJFXW6xQf"
      },
      "id": "NQ8hJFXW6xQf",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_train = 0.7\n",
        "n_train_samples =  int(len(ds) * split_train)\n",
        "print(f\"Use {n_train_samples} samples as training data\")\n",
        "\n",
        "split_val = 0.2\n",
        "n_val_samples = int(len(ds) * split_val)\n",
        "print(f\"Use {n_val_samples} samples as validation data\")\n",
        "\n",
        "split_test = 1 - (split_train + split_val)\n",
        "print(f\"The remaining {len(ds)- (n_train_samples+n_val_samples)} samples will be used as test data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0SgFkcV6-R-",
        "outputId": "25a39ff8-4143-43df-8ee8-5a3e80179f79"
      },
      "id": "y0SgFkcV6-R-",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 1693 samples as training data\n",
            "Use 483 samples as validation data\n",
            "The remaining 243 samples will be used as test data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ds.take(n_train_samples)\n",
        "val_ds = ds.skip(n_train_samples)\n",
        "val_ds = val_ds.take(n_val_samples)\n",
        "test_ds = ds.skip(n_train_samples + n_val_samples)"
      ],
      "metadata": {
        "id": "olOFRpEs7EFf"
      },
      "id": "olOFRpEs7EFf",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds  = train_ds.shuffle(buffer_size = len(train_ds))"
      ],
      "metadata": {
        "id": "xf9e6sKO7REn"
      },
      "id": "xf9e6sKO7REn",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "train_ds = train_ds.batch(BATCH_SIZE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)\n",
        "\n",
        "print (f' There are {len(train_ds)} training batches.')\n",
        "print (f' There are {len(val_ds)} validation batches.')\n",
        "print (f' There are {len(test_ds)} testing batches.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIFuwW7e7Tih",
        "outputId": "39249969-c45e-44c7-de29-c10f092ad230"
      },
      "id": "GIFuwW7e7Tih",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There are 1693 training batches.\n",
            " There are 483 validation batches.\n",
            " There are 243 testing batches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the data"
      ],
      "metadata": {
        "id": "s3KL9DEI7Yjc"
      },
      "id": "s3KL9DEI7Yjc",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_X, example_y= train_ds.take(1).get_single_element()\n",
        "print(example_X)\n",
        "print(example_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gaRZcTb7fh5",
        "outputId": "2a0c0c49-c355-422d-a91e-95db3486c690"
      },
      "id": "9gaRZcTb7fh5",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'We have yet another movie where it is getting high praise for reasons of politics...and possibly because Jamie Lee Curtis is back...but mainly for politics.\\r\\n\\r\\nBut it was really nice seeing Jamie Lee Curtis back, and nice in the \"it doesn\\'t really feel like a Halloween movie without her in it\" kind of way.\\r\\n\\r\\nUnfortunately that isn\\'t enough to save the film, nor is the added over-the-top blood and gore that didn\\'t really need a place in the first two movies.\\r\\n\\r\\nBut...the blood and gore seemed to replace real scares (though there were a couple) as if to say, yeah, they understand that they aren\\'t making this horror movie frightening, so they might as well make it bloodier and hope that it\\'s a decent trade off for actual scares.\\r\\n\\r\\nThe main issue, however, is that it is spread thin. It\\'s like it was written in committee where everyone that there little plot be added to the film despite how difficult that would make actual story telling.\\r\\n\\r\\nThe results are so many tiny little subplots that you end up not even caring about the main plot as they try to cram them all into the same hole. You end up just not caring at all about any of it.\\r\\n\\r\\nAnd then the characters shoved into the movie to accommodate the extra plot lines are just as thin and under-developed that it\\'s really hard to care about what happens to them as well.\\r\\n\\r\\nIn the end there is so much going on that it never really focuses enough on anything to keep the audience emotionally invested and really you end up only caring about Jamie because she won you over in the first two good films and that kind of holds you just enough to actually finish a film.\\r\\n\\r\\nIf she weren\\'t cast in it, even her character would be hard to relate to in any way.\\r\\n\\r\\nIt makes you want to take the director by the collar and yell \"focus!\" with the hopes that it would drop all the unnecessary story lines and just deal with what matters.\\r\\n\\r\\nBut, you know, there are the political signaling, and for a lot of people that matters more than story telling.\\r\\n\\r\\nFor everyone else, there is about 15 minutes, maybe, of actual focused plot and the rest is all tangential.'], shape=(1,), dtype=string)\n",
            "tf.Tensor([1], shape=(1,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    output_mode=\"count\"\n",
        ")"
      ],
      "metadata": {
        "id": "wRT7EmRZ7bgg"
      },
      "id": "wRT7EmRZ7bgg",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx1jkK4t7ewk",
        "outputId": "3f6f38d9-8d99-4742-fe4c-ae307978c1fe"
      },
      "id": "Bx1jkK4t7ewk",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.adapt(ds_texts)"
      ],
      "metadata": {
        "id": "jGOLLjeL7z5E"
      },
      "id": "jGOLLjeL7z5E",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = count_vectorizer.get_vocabulary()\n",
        "\n",
        "type(vocab), len(vocab), vocab[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fySFv-Vw716w",
        "outputId": "6774bd65-2267-44e1-f27f-63b7db7d2110"
      },
      "id": "fySFv-Vw716w",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 24922, ['[UNK]', 'the', 'and', 'a', 'of', 'to'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Vectorization Layer\n",
        "tfidf_vectorizer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    output_mode=\"tf_idf\",\n",
        ")\n",
        "# Vectorizer vocab\n",
        "tfidf_vectorizer.adapt(ds_texts)\n",
        "# Confrim vocab size\n",
        "tfidf_vectorizer.vocabulary_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1t4FaW-75a2",
        "outputId": "206f4995-ee8a-4f1a-97bd-7d603caf113a"
      },
      "id": "o1t4FaW-75a2",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24922"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = sequence_vectorizer.vocabulary_size()\n",
        "VOCAB_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xby7EnfB8Bqy",
        "outputId": "b63f6550-e836-47e9-c2b7-329d4678487d"
      },
      "id": "Xby7EnfB8Bqy",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24923"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 100"
      ],
      "metadata": {
        "id": "cL8JwQcp-Mn4"
      },
      "id": "cL8JwQcp-Mn4",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 400"
      ],
      "metadata": {
        "id": "feSkrfL1-T8Z"
      },
      "id": "feSkrfL1-T8Z",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = y.unique()\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37nJws7J-sha",
        "outputId": "9bb0bdc0-f9f8-4bf4-fce7-e0fd9c2e3209"
      },
      "id": "37nJws7J-sha",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_lstm_model(text_vectorization_layer):\n",
        "\n",
        "    lstm_model = Sequential([\n",
        "        text_vectorization_layer,\n",
        "        layers.Embedding(input_dim=VOCAB_SIZE,\n",
        "                                  output_dim=EMBED_DIM,\n",
        "                                  input_length=SEQUENCE_LENGTH)\n",
        "        ])\n",
        "\n",
        "    lstm_model.add(layers.LSTM(128))\n",
        "    lstm_model.add(layers.Dense(len(classes), activation='softmax'))\n",
        "\n",
        "    lstm_model.compile(optimizer=optimizers.legacy.Adam(learning_rate = .01),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    lstm_model.summary()\n",
        "    return lstm_model"
      ],
      "metadata": {
        "id": "ThJfZlGy9Pty"
      },
      "id": "ThJfZlGy9Pty",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
        "    return [early_stop]"
      ],
      "metadata": {
        "id": "CEHS6ABr9fV-"
      },
      "id": "CEHS6ABr9fV-",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm model\n",
        "lstm_model = build_lstm_model(sequence_vectorizer)\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "history = lstm_model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=get_callbacks(),\n",
        ")\n",
        "\n",
        "results = fn.evaluate_classification_network(\n",
        "    lstm_model, X_train=train_ds,\n",
        "    X_test=test_ds, history=history\n",
        ");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a-Wy6lp9yu-",
        "outputId": "91385be2-5393-4748-9aa1-a0fb43ea8343"
      },
      "id": "1a-Wy6lp9yu-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_2 (Text  (None, 30)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 30, 100)           2492300   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               117248    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2609806 (9.96 MB)\n",
            "Trainable params: 2609806 (9.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1693/1693 [==============================] - 153s 89ms/step - loss: 0.7755 - accuracy: 0.5103 - val_loss: 0.7453 - val_accuracy: 0.4948\n",
            "Epoch 2/30\n",
            "1693/1693 [==============================] - 136s 80ms/step - loss: 0.7556 - accuracy: 0.5322 - val_loss: 0.8190 - val_accuracy: 0.5052\n",
            "Epoch 3/30\n",
            "1693/1693 [==============================] - 138s 82ms/step - loss: 0.6669 - accuracy: 0.6828 - val_loss: 0.9134 - val_accuracy: 0.5280\n",
            "Epoch 4/30\n",
            " 147/1693 [=>............................] - ETA: 2:06 - loss: 0.5437 - accuracy: 0.7279"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ga7496vo90kB"
      },
      "id": "ga7496vo90kB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (dojo-env)",
      "language": "python",
      "name": "dojo-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}